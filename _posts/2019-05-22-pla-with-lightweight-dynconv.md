---
layout: post
title: "关于light weight和dynamic convolution"
date: 2019-05-16
---
* [PAY LESS ATTENTION WITH LIGHTWEIGHT AND DYNAMIC CONVOLUTGIONS]

    这篇论文关注通过lightweight convolutions和dynamica convolutions来解决MT中较长序列问题，降低网络参数，提升训练速度。


    * Transformer

        <img src="https://github.com/yingzgigi/yingzgigi.github.io/blob/master/_posts/postsimage/transformer.png" alt="Transformer" title="Transformer" width="50" height="50" />

        Transformer可以用来解决自然语言不定长问题，跟CNN类似，设定输入的最大长度，用Padding填充不够的部分，使模型输入定长。
    * Self Attention

    * Lightweight Convolution

    * Dynamic Convolution
  
    * Experiment

    * Results

    * Conclustion



